# Copyright 2024 DeepMind Technologies Limited
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

"""Compute metrics on the saved outputs of a TAP-3D model."""

import utils.metrics as metrics
import os
import glob
import numpy as np
import tqdm
import io
from PIL import Image
from absl import logging

ZERO_METRICS_DICT = {
    'occlusion_accuracy': np.array([0.0]),
    'pts_within_1': np.array([0.0]),
    'jaccard_1': np.array([0.0]),
    'pts_within_2': np.array([0.0]),
    'jaccard_2': np.array([0.0]),
    'pts_within_4': np.array([0.0]),
    'jaccard_4': np.array([0.0]),
    'pts_within_8': np.array([0.0]),
    'jaccard_8': np.array([0.0]),
    'pts_within_16': np.array([0.0]),
    'jaccard_16': np.array([0.0]),
    'average_jaccard': np.array([0.0]),
    'average_pts_within_thresh': np.array([0.0]),
}

def get_new_hw_with_given_smallest_side_length(
    *, orig_height: int, orig_width: int, smallest_side_length: int = 256
):
  orig_shape = np.array([orig_height, orig_width])
  scaling_factor = smallest_side_length / np.min(orig_shape)
  resized_shape = np.round(orig_shape * scaling_factor)
  return (int(resized_shape[0]), int(resized_shape[1])), scaling_factor

def get_jpeg_byte_hw(jpeg_bytes: bytes):
    with io.BytesIO(jpeg_bytes) as img_bytes:
        img = Image.open(img_bytes)
        img = img.convert('RGB')
        shape = np.array(img).shape[:2]
        img.close()  # 在返回前关闭图像对象
    return shape


def get_average_over_metrics(
    list_of_metrics: list[dict[str, dict[str, np.ndarray]]]
):
  """Average over per video metrics in a nested metrics dictionaries."""
  avg_metrics = {}
  for metric_category in list_of_metrics[0].keys():
    avg_metrics[metric_category] = {}
    for metric_name in list_of_metrics[0][metric_category]:
      avg_metrics[metric_category][metric_name] = np.mean(
          [
              video_metric[metric_category][metric_name]
              for video_metric in list_of_metrics
          ]
      )
  return avg_metrics

def evaluate_data_source(
    npz_filenames: list[str],
    ground_truth_dir: str,
    predictions_dir: str,
    depth_scalings: list[str],
    metric_eval_resolution: int = 256,
) -> dict[str, dict[str, np.ndarray]]:
  """Compute metrics on the set of 3D track predictions.

  This function expects as input two directories: `ground_truth_dir` and
  `predictions_dir`. They should have a structure as follows:

    - ground_truth_dir:
        - video1.npz (with contents+format described in tapvid3d/README.md)
        - video2.npz
        - video3.npz
        - ...
        - videoN.npz

    - predictions_dir:
        - video1.npz (contains two tensors: the predicted `visibility` and
                      `tracks_XYZ`, with shapes described in tapvid3d/README.md)
        - video2.npz
        - video3.npz
        - ...
        - videoN.npz

  `ground_truth_dir` contains npz files with ground truth data, while
  `predictions_dir` should contains npz files with the same file name as their
  corresponding ground truth file in `ground_truth_dir`. npz files can be named
  anything (do not need to be named as video{N}.npz in the example), as long
  as it is consistent across both directories.

  Also note that this directory structure (for `ground_truth_dir`) is what is
  generated by `generate_all.sh` script. The script generates three different
  directories: `tapvid3d_dataset/adt`, `tapvid3d_dataset/pstudio`,
  `tapvid3d_dataset/drivetrack`, each one with the structure described above.

  Args:
    npz_filenames: List of npz file names to compute metrics over.
                   Each filename must exist in both `ground_truth_dir` and
                   `predictions_dir`.
    ground_truth_dir: Path to the TAP-3D dataset, format described above.
    predictions_dir: Path to the TAP-3D predictions, format described above.
    depth_scalings: List of strings, describing which depth scaling strategies
                   to use. See `compute_tapvid3d_metrics()` in metrics.py for
                   available scaling options and their descriptions.
    metric_eval_resolution: The resolution at which to evaluate the metrics,
                            by default is 256, which is used for all results
                            in the TAPVid-3D paper and original TAPVid paper.

  Returns:
    A dictionary of dictionaries: the outer dict mapping different
    depth scaling strategies to an inner metrics dict (mapping a metric name
    to the corresponding metric score).
  """
  metrics_all_videos = []
  for npy_file in tqdm.tqdm(npz_filenames, total=len(npz_filenames)):
    gt_file = os.path.join(ground_truth_dir, npy_file)
    start_frame = 1
    with open(gt_file, 'rb') as in_f:
      in_npz = np.load(in_f, allow_pickle=True)
      images_jpeg_bytes = in_npz['images_jpeg_bytes'][start_frame:]
      queries_xyt = in_npz['queries_xyt']
      tracks_xyz = in_npz['tracks_XYZ'][start_frame:]
      visibles = in_npz['visibility'][start_frame:]
      intrinsics_params = in_npz['fx_fy_cx_cy']

    # Simple rescaling from original video resolution to the resolution
    # at which we want to compute the metrics (metric_eval_resolution)
    # Since camera intrinsics are for original video resolution, we need to
    # rescale them as well.
    # `intrinsics_params` is in format [fx, fy, cx, cy].
    video_height, video_width = get_jpeg_byte_hw(images_jpeg_bytes[0])
    smallest_side_length = metric_eval_resolution
    (_, _), scaling_factor = (
        get_new_hw_with_given_smallest_side_length(
            orig_height=video_height,
            orig_width=video_width,
            smallest_side_length=smallest_side_length,
        )
    )
    intrinsics_params_resized = intrinsics_params * scaling_factor

    prediction_file = os.path.join(predictions_dir, npy_file)
    try:
      with open(prediction_file, 'rb') as in_f:
        predictor_data = np.load(in_f, allow_pickle=True)
        predicted_tracks_xyz = predictor_data['tracks_XYZ'][start_frame:]
        predicted_visibility = predictor_data['visibility'][start_frame:]

    except Exception:  # pylint: disable=broad-exception-caught
      logging.exception('Failed to read %s', prediction_file)
      failure_metrics_dict = {
          scaling: ZERO_METRICS_DICT for scaling in depth_scalings
      }
      metrics_all_videos.append(failure_metrics_dict)
      continue

    video_metrics = {}
    for depth_scaling in depth_scalings:
      try:
        metrics_for_scale = metrics.compute_tapvid3d_metrics(
            gt_occluded=np.logical_not(visibles),
            gt_tracks=tracks_xyz,
            pred_occluded=np.logical_not(predicted_visibility),
            pred_tracks=predicted_tracks_xyz,
            intrinsics_params=intrinsics_params_resized,
            scaling=depth_scaling,
            query_points=queries_xyt[..., ::-1],
            order='t n',
        )
      except Exception:  # pylint: disable=broad-exception-caught
        logging.exception('Failed to compute metrics for %s', npy_file)
        metrics_for_scale = ZERO_METRICS_DICT
      video_metrics[depth_scaling] = metrics_for_scale
    metrics_all_videos.append(video_metrics)

  avg_metrics = get_average_over_metrics(metrics_all_videos)
  return avg_metrics


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="Tracking Evaluation")
    parser.add_argument('--gt_dir', type=str, required=True, help='Path to the gt datqa')
    parser.add_argument('--pred_dir', type=str, required=True, help='Path to pred data')
    parser.add_argument('--dataset', type=str, required=True, help='Dataset name')
    args = parser.parse_args()
    
    datasets = args.dataset.split(',')
    for data_source in datasets:
        source_gt_dir = os.path.join(args.gt_dir, data_source)
        source_pred_dir = os.path.join(args.pred_dir, data_source)
        
        all_npz_files = glob.glob(os.path.join(source_gt_dir, '**', '*'), recursive=True)
        all_npz_files = [os.path.basename(f) for f in all_npz_files]
        
        source_metrics = evaluate_data_source(
            npz_filenames=all_npz_files,
            ground_truth_dir=source_gt_dir,
            predictions_dir=source_pred_dir,
            depth_scalings=['median'],
        )
        print('Metrics for data source %s', data_source)
        print(source_metrics)